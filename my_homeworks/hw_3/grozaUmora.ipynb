{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e43975",
   "metadata": {},
   "source": [
    "### Дообучение модели для генерации анекдотов \n",
    "\n",
    "Используется модель: Qwen3-0.6B (Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, List, Iterable, Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "rng = random.Random(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24215c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/michaelstepanovsky/anecdoted?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.27M/5.27M [00:01<00:00, 4.34MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub \n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"michaelstepanovsky/anecdoted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b3d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files:  [WindowsPath('C:/Users/user/.cache/kagglehub/datasets/michaelstepanovsky/anecdoted/versions/1/anecdotes_dataset.csv')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Нижегородский купчина рассказывает своим друзь...</td>\n",
       "      <td>71</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Папа, а марсиане есть?- Нет, сынок, кончилис...</td>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Где работает ваш муж?- Уже третий месяц на л...</td>\n",
       "      <td>28</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Дорогой, я похожа на идеальную женщину ?- Не...</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- О, милая! Панировка этих котлет такая хрустя...</td>\n",
       "      <td>30</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                joke  word_count  char_count\n",
       "0  Нижегородский купчина рассказывает своим друзь...          71         358\n",
       "1  - Папа, а марсиане есть?- Нет, сынок, кончилис...          21          78\n",
       "2  - Где работает ваш муж?- Уже третий месяц на л...          28         126\n",
       "3  - Дорогой, я похожа на идеальную женщину ?- Не...          29         111\n",
       "4  - О, милая! Панировка этих котлет такая хрустя...          30         144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего анекдотов:  44108\n"
     ]
    }
   ],
   "source": [
    "root = Path(path)\n",
    "csv_files = sorted(root.rglob(\"*.csv\"), key=lambda p: p.stat().st_size, reverse=True)\n",
    "\n",
    "print(\"files: \", csv_files)\n",
    "\n",
    "dataset = pd.read_csv(csv_files[0])\n",
    "\n",
    "display(dataset.head(5))\n",
    "\n",
    "print(\"Всего анекдотов: \", dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c0331bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 Идёт мужик по лесу\\n', '2 Встречаются два друга\\n', '3 Приходят мужик в бар\\n', '4 Жена говорит мужу\\n', '5 Приходят альфа, бета и гамма в бар\\n']\n"
     ]
    }
   ],
   "source": [
    "# сетапы\n",
    "with open(\"data/prefixes.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prefixes = f.readlines()\n",
    "\n",
    "\n",
    "print(prefixes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9702960",
   "metadata": {},
   "source": [
    "Формализовать задачу можно следующим образом: дан набор сетапов, к которым необходимо дописать панчлайн. Следовательно, необходимо ставить перед моделью задачу \"сетап -> панчлайн\" -> loss считать на панчлайнах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b2bed",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "\n",
    "В анекдоте сетап часто = первая фраза/первая реплика/первые N слов, а панчлайн = всё остальное\n",
    "\n",
    "Тестовый вход: “Идёт мужик по лесу” (без контекста).\n",
    "\n",
    "Значит в обучении должны быть такие же короткие входы\n",
    "\n",
    "Будем собирать анекдоты по следующему шаблону:\n",
    "\n",
    "    Сетап: <setup>\n",
    "    Панчлайн: <punchline>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c6cc9",
   "metadata": {},
   "source": [
    "### Подготовка сетапов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ad6bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_id_and_text(s: str) -> Tuple[Optional[int], str]:\n",
    "    \"Разбивает сетапы на id и текст\"\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").strip()\n",
    "    parts = s.split(\" \", 1)\n",
    "    head, rest = parts[0], parts[1]\n",
    "    \n",
    "    return int(head), rest.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5997321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Идёт мужик по лесу', 'Встречаются два друга', 'Приходят мужик в бар', 'Жена говорит мужу', 'Приходят альфа, бета и гамма в бар', 'Идёт медведь по лесу', 'Приходит мужик к врачу', 'Встречаются русский, американец и немец', 'Идёт по улице девушка', 'Приходит мужик в магазин', 'Еще сто лет назад', 'Встречаются Вовочка и Петька', 'Идёт по лесу охотник', 'Я хорошо готовлю, стираю и убираю в квартире', 'Жена спрашивает у мужа', 'Сидят в баре два друга', 'Идёт по пустыне караван', 'Приходит мужик в аптеку', 'Встречаются два программиста', '- Послушайте, у этого парня в резюме', 'Приходит мужик в банк', 'Сидят на скамейке два пенсионера', 'Идёт по лесу грибник', 'Приходит мужик в ресторан', '- Я дочитал учебник по теории вероятности', 'Идёт по улице студент', 'Заходит студент в кофейню', 'Сидят в очереди два человека', 'Идёт по лесу шаман', 'Приходит мужик в библиотеку', 'Идёт по улице кот', 'Встречаются два математика', 'Приходит программист в бар', 'Сидит кот на клавиатуре', 'Доказывает теорему математик', 'Пишет код программист', 'Спрашивает LLM у пользователя', 'Встречаются feature engineer и data scientist', 'Решает уравнение студент', 'Вышел новый альбом Оксимирона', 'Говорит кот хозяину', 'Простой способ остудить чай', 'Доказывает математик теорему', 'Спрашивает математик у кота', 'Пишет промпт для LLM', 'Сидит кот перед монитором', 'Объясняет математик программисту', 'Наняли команду 40 программистов', 'Идёт по крыше кот', 'В статье было написано', 'Спрашивает кот у математика', 'Думает программист о баге', 'Общается пользователь с LLM', 'Сидит кот на книге по алгоритмам', 'Пишет программист тесты', 'Решает LLM задачу по математике', 'Я прочитал книгу Пелевина', 'Встречаются два кота', 'Доказывает программист, что кот - это баг', 'Как часто девушки думают о', 'Примерно двадцать лет назад', 'Классический ML', 'Узнал сегодня забавный факт', 'Я хотел быть самим собой, обычным пацаном', 'За окном шумит Сургут', 'Вообще я люблю только две вещи:', 'Хороший русский рэп', 'Одна бессмысленная ночь у телефона', 'В России запретили', 'Из характеристики:', 'Встречаются overfitting и underfitting', 'Идёт по дому кошка', 'Я из тех людей', '- Я нормальный.', 'Есть только одна система:']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 80, 81, 82, 83]\n"
     ]
    }
   ],
   "source": [
    "setups = [split_id_and_text(p)[1] for p in prefixes]\n",
    "ids = [split_id_and_text(p)[0] for p in prefixes]\n",
    "\n",
    "print(setups) \n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306363db",
   "metadata": {},
   "source": [
    "### Подготовка анекдотов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a159209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# шаблоны для разбиения\n",
    "\n",
    "_SENT_SPLIT_RE = re.compile(r\"(?<=[.!?])\\s+\")\n",
    "_DASH_RE = re.compile(r\"\\s*[-—]\\s*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2be72bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_setup_punchline(text: str) -> Optional[Tuple[str, str]]:\n",
    "    \"\"\"Функция для разбиения анекдота на сетап/панчлайн\n",
    "    Args:\n",
    "        text (str): Анекдот\n",
    "        \n",
    "    Returns:\n",
    "        Optional[Tuple[str, str]]: Пару (сетап, панчлайн). Если разбить анекдот не получилось, возвращает None\"\"\"\n",
    "    t = text.strip()\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # 1) Если многострочный — первая строка сетап\n",
    "    if \"\\n\" in t:\n",
    "        lines = [x.strip() for x in t.split(\"\\n\") if x.strip()]\n",
    "        if len(lines) >= 2:\n",
    "            setup = lines[0]\n",
    "            punch = \" \".join(lines[1:]).strip()\n",
    "            if len(setup) >= 8 and len(punch) >= 8:\n",
    "                return setup, punch\n",
    "\n",
    "    # 2) Если есть явный диалог/тире — берём кусок до первого \"—\" как сетап (часто работает)\n",
    "    if \"—\" in t or \" - \" in t:\n",
    "        parts = _DASH_RE.split(t, maxsplit=1)\n",
    "        if len(parts) == 2:\n",
    "            setup = parts[0].strip()\n",
    "            punch = (\"— \" + parts[1].strip()).strip()\n",
    "            if len(setup) >= 8 and len(punch) >= 8:\n",
    "                return setup, punch\n",
    "\n",
    "    # 3) По первой фразе\n",
    "    sents = _SENT_SPLIT_RE.split(t)\n",
    "    if len(sents) >= 2:\n",
    "        setup = sents[0].strip()\n",
    "        punch = \" \".join(sents[1:]).strip()\n",
    "        if len(setup) >= 8 and len(punch) >= 8:\n",
    "            return setup, punch\n",
    "\n",
    "    # 4) По словам (fallback)\n",
    "    words = t.split()\n",
    "    if len(words) >= 12:\n",
    "        k = min(10, max(5, len(words) // 3))\n",
    "        setup = \" \".join(words[:k])\n",
    "        punch = \" \".join(words[k:])\n",
    "        if len(setup) >= 8 and len(punch) >= 8:\n",
    "            return setup, punch\n",
    "\n",
    "    return None\n",
    "\n",
    "def make_prefix_splits(text: str, n_variants: int = 2):\n",
    "    \"\"\"Делаем несколько вариантов: сетап = первые k слов, панчлайн = хвост.\"\"\"\n",
    "    t = text.strip()\n",
    "    words = t.split()\n",
    "    out = []\n",
    "    if len(words) < 14:\n",
    "        return out\n",
    "    for _ in range(n_variants):\n",
    "        k = random.randint(4, min(12, len(words) - 8))\n",
    "        setup = \" \".join(words[:k])\n",
    "        punch = \" \".join(words[k:])\n",
    "        if len(setup) >= 8 and len(punch) >= 8:\n",
    "            out.append((setup, punch))\n",
    "    return out\n",
    "\n",
    "def canonicalize_setup(setup: str, setups: List[str]):\n",
    "    \"\"\"Если сетап похож на один из тестовых — приводим к канонической форме.\"\"\"\n",
    "    s = setup.strip().lower()\n",
    "    for canon in setups:\n",
    "        c = canon.lower()\n",
    "        if s.startswith(c):\n",
    "            return canon\n",
    "    return setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for t in dataset[\"joke\"].tolist():\n",
    "    sp = split_setup_punchline(t)\n",
    "    if sp is not None:\n",
    "        setup, punch = sp\n",
    "        setup = canonicalize_setup(setup, setups)\n",
    "        pairs.append((setup, punch))\n",
    "\n",
    "    for setup, punch in make_prefix_splits(t, n_variants=2):\n",
    "        setup = canonicalize_setup(setup, setups)\n",
    "        pairs.append((setup, punch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96295727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сформировано пар (setup, punchline): 111604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Нижегородский купчина рассказывает своим друзьям',\n",
       "  '— купцам:- Не люблю я англичан! Сумасшедший народ! Я в Питере был, в гостинице по соседству с англичанином жил - никакого житья: без конца то горло полощет, то вообще неприличные звуки издаёт..- А вы уверены, что это был англичанин?- Ну как же! У него на двери и табличка висела с именем-фамилией: Уотер Клозет.'),\n",
       " ('Нижегородский купчина рассказывает своим друзьям-купцам:- Не люблю я англичан! Сумасшедший народ! Я',\n",
       "  'в Питере был, в гостинице по соседству с англичанином жил - никакого житья: без конца то горло полощет, то вообще неприличные звуки издаёт..- А вы уверены, что это был англичанин?- Ну как же! У него на двери и табличка висела с именем-фамилией: Уотер Клозет.'),\n",
       " ('Нижегородский купчина рассказывает своим друзьям-купцам:- Не',\n",
       "  'люблю я англичан! Сумасшедший народ! Я в Питере был, в гостинице по соседству с англичанином жил - никакого житья: без конца то горло полощет, то вообще неприличные звуки издаёт..- А вы уверены, что это был англичанин?- Ну как же! У него на двери и табличка висела с именем-фамилией: Уотер Клозет.'),\n",
       " ('- Папа, а марсиане есть?-',\n",
       "  'Нет, сынок, кончились, на вот, возьми сыру покушай!'),\n",
       " ('- Где работает ваш муж?- Уже третий месяц на ликеро-водочном заводе.- И ему там нравится?- Не знаю.',\n",
       "  'Он еще не приходил домой.'),\n",
       " ('- Где работает ваш муж?- Уже третий месяц на ликеро-водочном',\n",
       "  'заводе.- И ему там нравится?- Не знаю. Он еще не приходил домой.'),\n",
       " ('- Где работает ваш муж?-',\n",
       "  'Уже третий месяц на ликеро-водочном заводе.- И ему там нравится?- Не знаю. Он еще не приходил домой.'),\n",
       " ('- Дорогой, я похожа на идеальную женщину ?- Нет, ты нечто большее!- Да?',\n",
       "  'И насколько?- Ну, килограммов на 50...'),\n",
       " ('- Дорогой, я похожа на идеальную женщину ?- Нет, ты',\n",
       "  'нечто большее!- Да? И насколько?- Ну, килограммов на 50...'),\n",
       " ('- Дорогой, я похожа на идеальную женщину ?- Нет,',\n",
       "  'ты нечто большее!- Да? И насколько?- Ну, килограммов на 50...')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = list(dict.fromkeys(pairs)) # drop duplicates\n",
    "\n",
    "print(\"Сформировано пар (setup, punchline):\", len(pairs))\n",
    "\n",
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb9b76b",
   "metadata": {},
   "source": [
    "### Подготовка к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(s: str) -> str:\n",
    "    return str(s).replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").strip()\n",
    "\n",
    "def build_prompt(setup: str) -> str:\n",
    "    # только сетап\n",
    "    s = norm(setup)\n",
    "    return s\n",
    "\n",
    "def build_completion(punchline: str) -> str:\n",
    "    # Ведущий пробел помогает сделать границу prompt|completion стабильной\n",
    "    # и избегает “склейки” слов, если сетап без пробела на конце.\n",
    "    c = norm(punchline)\n",
    "    return \" \" + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c21c1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for setup, punch in pairs:\n",
    "    p = build_prompt(setup)\n",
    "    c = build_completion(punch)\n",
    "    if len(p) == 0 or len(c.strip()) == 0:\n",
    "        continue\n",
    "    rows.append({\"prompt\": p, \"completion\": c})\n",
    "\n",
    "pc_ds = Dataset.from_list(rows).shuffle(seed=42)\n",
    "splits = pc_ds.train_test_split(test_size=0.01, seed=42)\n",
    "train_pc, eval_pc = splits[\"train\"], splits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "259914eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Приходит Василий Иванович домой пьяный в дым, а Петька сидит дома трезвый, злой Думает:',\n",
       " 'completion': ' — Ну ладно, попомню я тебе это Взял пластилин и Чапаю второй член из него вылепил, прилепил и спать лег Среди ночи Петька просыпается от истошного крика и понять ничего не может, забыл-то уже, что ночью вытворил А Чапай сидит посреди комнаты и орет: - Петька, пить бросаю, не поверишь, просыпаюсь, а у меня два члена Я один оторвал, а второй сам отпал.'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pc[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d43195",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a56540dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-0.6B-Base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "15c45e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "75b3b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bf16_ok = use_cuda and torch.cuda.is_bf16_supported()\n",
    "dtype = torch.bfloat16 if bf16_ok else (torch.float16 if use_cuda else torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d7cee3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b4d0e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "da1d101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=\"all-linear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e518ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "    output_dir=\"qwen3-punchlines-sft\",\n",
    "    max_length=256,                \n",
    "    packing=False,                  \n",
    "    completion_only_loss=True,      \n",
    "\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "\n",
    "    per_device_train_batch_size=8 if use_cuda else 1,\n",
    "    gradient_accumulation_steps=2 if use_cuda else 4,\n",
    "\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=250,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    report_to=[],\n",
    "    bf16=(dtype == torch.bfloat16),\n",
    "    fp16=(dtype == torch.float16),\n",
    "    max_grad_norm=1.0,\n",
    "    group_by_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c5c73859",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = set(inspect.signature(SFTConfig.__init__).parameters.keys())\n",
    "cfg = {k: v for k, v in cfg.items() if k in sig}\n",
    "\n",
    "args = SFTConfig(**cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fca1e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding EOS to train dataset: 100%|██████████| 110487/110487 [00:03<00:00, 34586.92 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 110487/110487 [00:25<00:00, 4314.85 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 110487/110487 [00:00<00:00, 1365679.62 examples/s]\n",
      "Adding EOS to eval dataset: 100%|██████████| 1117/1117 [00:00<00:00, 25601.02 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 1117/1117 [00:00<00:00, 3298.35 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 1117/1117 [00:00<00:00, 557079.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_pc,\n",
    "    eval_dataset=eval_pc,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "476d7ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13812' max='13812' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13812/13812 2:44:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.805200</td>\n",
       "      <td>2.913895</td>\n",
       "      <td>2.943386</td>\n",
       "      <td>338136.000000</td>\n",
       "      <td>0.415383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.863600</td>\n",
       "      <td>2.844347</td>\n",
       "      <td>2.874017</td>\n",
       "      <td>682057.000000</td>\n",
       "      <td>0.424938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.675100</td>\n",
       "      <td>2.759075</td>\n",
       "      <td>2.838589</td>\n",
       "      <td>1025786.000000</td>\n",
       "      <td>0.439222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.767300</td>\n",
       "      <td>2.713129</td>\n",
       "      <td>2.786627</td>\n",
       "      <td>1373362.000000</td>\n",
       "      <td>0.446107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.622400</td>\n",
       "      <td>2.666569</td>\n",
       "      <td>2.754129</td>\n",
       "      <td>1717359.000000</td>\n",
       "      <td>0.453535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.656800</td>\n",
       "      <td>2.639953</td>\n",
       "      <td>2.649875</td>\n",
       "      <td>2055058.000000</td>\n",
       "      <td>0.459072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.599500</td>\n",
       "      <td>2.611976</td>\n",
       "      <td>2.635431</td>\n",
       "      <td>2392357.000000</td>\n",
       "      <td>0.462832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.555100</td>\n",
       "      <td>2.582747</td>\n",
       "      <td>2.625834</td>\n",
       "      <td>2728120.000000</td>\n",
       "      <td>0.466720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>2.503300</td>\n",
       "      <td>2.551079</td>\n",
       "      <td>2.577734</td>\n",
       "      <td>3071381.000000</td>\n",
       "      <td>0.473471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.580400</td>\n",
       "      <td>2.520362</td>\n",
       "      <td>2.584360</td>\n",
       "      <td>3411977.000000</td>\n",
       "      <td>0.478970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>2.442400</td>\n",
       "      <td>2.490662</td>\n",
       "      <td>2.582435</td>\n",
       "      <td>3758856.000000</td>\n",
       "      <td>0.485932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.480800</td>\n",
       "      <td>2.469573</td>\n",
       "      <td>2.563920</td>\n",
       "      <td>4100285.000000</td>\n",
       "      <td>0.488397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>2.381600</td>\n",
       "      <td>2.441610</td>\n",
       "      <td>2.470679</td>\n",
       "      <td>4442978.000000</td>\n",
       "      <td>0.493485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.433900</td>\n",
       "      <td>2.420167</td>\n",
       "      <td>2.474680</td>\n",
       "      <td>4785592.000000</td>\n",
       "      <td>0.496177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>2.367300</td>\n",
       "      <td>2.389961</td>\n",
       "      <td>2.489310</td>\n",
       "      <td>5130439.000000</td>\n",
       "      <td>0.502052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.412100</td>\n",
       "      <td>2.369881</td>\n",
       "      <td>2.469885</td>\n",
       "      <td>5472877.000000</td>\n",
       "      <td>0.506817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>2.258700</td>\n",
       "      <td>2.346629</td>\n",
       "      <td>2.380511</td>\n",
       "      <td>5815826.000000</td>\n",
       "      <td>0.512817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.343400</td>\n",
       "      <td>2.322299</td>\n",
       "      <td>2.392684</td>\n",
       "      <td>6154597.000000</td>\n",
       "      <td>0.516550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>2.234600</td>\n",
       "      <td>2.294574</td>\n",
       "      <td>2.397433</td>\n",
       "      <td>6498371.000000</td>\n",
       "      <td>0.518645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.356000</td>\n",
       "      <td>2.280317</td>\n",
       "      <td>2.390035</td>\n",
       "      <td>6846423.000000</td>\n",
       "      <td>0.522662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>2.200100</td>\n",
       "      <td>2.256390</td>\n",
       "      <td>2.381086</td>\n",
       "      <td>7186710.000000</td>\n",
       "      <td>0.526163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.231400</td>\n",
       "      <td>2.236302</td>\n",
       "      <td>2.324352</td>\n",
       "      <td>7533047.000000</td>\n",
       "      <td>0.529561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>2.187300</td>\n",
       "      <td>2.219990</td>\n",
       "      <td>2.302509</td>\n",
       "      <td>7871748.000000</td>\n",
       "      <td>0.533781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.223400</td>\n",
       "      <td>2.205576</td>\n",
       "      <td>2.335488</td>\n",
       "      <td>8210737.000000</td>\n",
       "      <td>0.535670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>2.139200</td>\n",
       "      <td>2.179218</td>\n",
       "      <td>2.390314</td>\n",
       "      <td>8553592.000000</td>\n",
       "      <td>0.539223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.199500</td>\n",
       "      <td>2.164100</td>\n",
       "      <td>2.355894</td>\n",
       "      <td>8895849.000000</td>\n",
       "      <td>0.543974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>2.036800</td>\n",
       "      <td>2.147643</td>\n",
       "      <td>2.311348</td>\n",
       "      <td>9231685.000000</td>\n",
       "      <td>0.546574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.827200</td>\n",
       "      <td>2.132900</td>\n",
       "      <td>2.254893</td>\n",
       "      <td>9577814.000000</td>\n",
       "      <td>0.549794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>1.866500</td>\n",
       "      <td>2.118345</td>\n",
       "      <td>2.213334</td>\n",
       "      <td>9919652.000000</td>\n",
       "      <td>0.554549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.797800</td>\n",
       "      <td>2.102469</td>\n",
       "      <td>2.202558</td>\n",
       "      <td>10256133.000000</td>\n",
       "      <td>0.557816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>1.899600</td>\n",
       "      <td>2.085073</td>\n",
       "      <td>2.201659</td>\n",
       "      <td>10598397.000000</td>\n",
       "      <td>0.560902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.771500</td>\n",
       "      <td>2.071009</td>\n",
       "      <td>2.214651</td>\n",
       "      <td>10942867.000000</td>\n",
       "      <td>0.564518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>1.832900</td>\n",
       "      <td>2.062588</td>\n",
       "      <td>2.201471</td>\n",
       "      <td>11283719.000000</td>\n",
       "      <td>0.566010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.734000</td>\n",
       "      <td>2.048534</td>\n",
       "      <td>2.181377</td>\n",
       "      <td>11624515.000000</td>\n",
       "      <td>0.567399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>1.814500</td>\n",
       "      <td>2.038986</td>\n",
       "      <td>2.163778</td>\n",
       "      <td>11964983.000000</td>\n",
       "      <td>0.571352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.785900</td>\n",
       "      <td>2.024581</td>\n",
       "      <td>2.182753</td>\n",
       "      <td>12306810.000000</td>\n",
       "      <td>0.572975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>1.798700</td>\n",
       "      <td>2.009941</td>\n",
       "      <td>2.174980</td>\n",
       "      <td>12649538.000000</td>\n",
       "      <td>0.576177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.680100</td>\n",
       "      <td>2.004911</td>\n",
       "      <td>2.162634</td>\n",
       "      <td>12989447.000000</td>\n",
       "      <td>0.577615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>1.774300</td>\n",
       "      <td>1.990860</td>\n",
       "      <td>2.164849</td>\n",
       "      <td>13329651.000000</td>\n",
       "      <td>0.579343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.682400</td>\n",
       "      <td>1.984488</td>\n",
       "      <td>2.142554</td>\n",
       "      <td>13674826.000000</td>\n",
       "      <td>0.581734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>1.734400</td>\n",
       "      <td>1.972612</td>\n",
       "      <td>2.154186</td>\n",
       "      <td>14018934.000000</td>\n",
       "      <td>0.584281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.607100</td>\n",
       "      <td>1.965284</td>\n",
       "      <td>2.136258</td>\n",
       "      <td>14359088.000000</td>\n",
       "      <td>0.585636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>1.739200</td>\n",
       "      <td>1.960521</td>\n",
       "      <td>2.143810</td>\n",
       "      <td>14708146.000000</td>\n",
       "      <td>0.587589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.608200</td>\n",
       "      <td>1.950099</td>\n",
       "      <td>2.140707</td>\n",
       "      <td>15049701.000000</td>\n",
       "      <td>0.588025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11250</td>\n",
       "      <td>1.762100</td>\n",
       "      <td>1.946689</td>\n",
       "      <td>2.136708</td>\n",
       "      <td>15394421.000000</td>\n",
       "      <td>0.589087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.661500</td>\n",
       "      <td>1.938704</td>\n",
       "      <td>2.141080</td>\n",
       "      <td>15739000.000000</td>\n",
       "      <td>0.590239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11750</td>\n",
       "      <td>1.719500</td>\n",
       "      <td>1.936283</td>\n",
       "      <td>2.136219</td>\n",
       "      <td>16080569.000000</td>\n",
       "      <td>0.590824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.641000</td>\n",
       "      <td>1.931213</td>\n",
       "      <td>2.128816</td>\n",
       "      <td>16423142.000000</td>\n",
       "      <td>0.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12250</td>\n",
       "      <td>1.702100</td>\n",
       "      <td>1.926206</td>\n",
       "      <td>2.134287</td>\n",
       "      <td>16767339.000000</td>\n",
       "      <td>0.593019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.631400</td>\n",
       "      <td>1.927612</td>\n",
       "      <td>2.128938</td>\n",
       "      <td>17101189.000000</td>\n",
       "      <td>0.592425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12750</td>\n",
       "      <td>1.675400</td>\n",
       "      <td>1.925744</td>\n",
       "      <td>2.131673</td>\n",
       "      <td>17446926.000000</td>\n",
       "      <td>0.592273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.615800</td>\n",
       "      <td>1.924225</td>\n",
       "      <td>2.128085</td>\n",
       "      <td>17786178.000000</td>\n",
       "      <td>0.593563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13250</td>\n",
       "      <td>1.727400</td>\n",
       "      <td>1.925541</td>\n",
       "      <td>2.129201</td>\n",
       "      <td>18123630.000000</td>\n",
       "      <td>0.593328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.592200</td>\n",
       "      <td>1.923558</td>\n",
       "      <td>2.129087</td>\n",
       "      <td>18467301.000000</td>\n",
       "      <td>0.593162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13750</td>\n",
       "      <td>1.686500</td>\n",
       "      <td>1.922732</td>\n",
       "      <td>2.127581</td>\n",
       "      <td>18809205.000000</td>\n",
       "      <td>0.594050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen/Qwen3-0.6B-Base/resolve/main/config.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1007)')))\"), '(Request ID: 7e05879f-8ab4-437b-a9f9-477c65144285)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen3-0.6B-Base/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13812, training_loss=2.1147494690334696, metrics={'train_runtime': 9879.8021, 'train_samples_per_second': 22.366, 'train_steps_per_second': 1.398, 'total_flos': 5.283486875477606e+16, 'train_loss': 2.1147494690334696, 'entropy': 2.3177488523980845, 'num_tokens': 18887096.0, 'mean_token_accuracy': 0.6162941067115121, 'epoch': 2.0})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2bf87ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qwen3-punchlines-lora\\\\tokenizer_config.json',\n",
       " 'qwen3-punchlines-lora\\\\special_tokens_map.json',\n",
       " 'qwen3-punchlines-lora\\\\chat_template.jinja',\n",
       " 'qwen3-punchlines-lora\\\\vocab.json',\n",
       " 'qwen3-punchlines-lora\\\\merges.txt',\n",
       " 'qwen3-punchlines-lora\\\\added_tokens.json',\n",
       " 'qwen3-punchlines-lora\\\\tokenizer.json')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(\"qwen3-punchlines-lora\")\n",
    "tokenizer.save_pretrained(\"qwen3-punchlines-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a61ca5",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd8496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— срать хочет, но не может - почему? Потому что он гей. Он в кустах сидит и думает: \"Если я утоплюсь, то будет африка\" Идет лес, и видит, а на дереве стоит другой мужик, и говорит: \"Деньги нужны, но топить\n"
     ]
    }
   ],
   "source": [
    "base_name = \"Qwen/Qwen3-0.6B\"\n",
    "tok = AutoTokenizer.from_pretrained(base_name, use_fast=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "dtype = torch.bfloat16 if (torch.cuda.is_available() and torch.cuda.is_bf16_supported()) else (\n",
    "    torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "base = AutoModelForCausalLM.from_pretrained(base_name, dtype=dtype).eval()\n",
    "\n",
    "\n",
    "model = PeftModel.from_pretrained(base, \"qwen3-punchlines-lora\").eval()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "def generate_punchline(setup: str, max_new_tokens: int = 80) -> str:\n",
    "    setup = setup.strip()\n",
    "    inputs = tok([setup], return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.5,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.08,\n",
    "        )\n",
    "    gen_ids = out[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    text = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "    # берём первую строку/фразу как “пончлайн”, чтобы не разгонялась\n",
    "    text = text.strip().split(\"\\n\")[0].strip()\n",
    "    return text\n",
    "\n",
    "print(generate_punchline(\"Идёт мужик по лесу\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8d6734b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating punchlines: 100%|██████████| 75/75 [07:10<00:00,  5.74s/it]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for item in tqdm(prefixes, total=len(prefixes), desc=\"Generating punchlines\"):\n",
    "    setup_id, setup_text = split_id_and_text(item)\n",
    "\n",
    "    setup_text = setup_text.strip()\n",
    "    if not setup_text:\n",
    "        continue\n",
    "\n",
    "    out = generate_punchline(setup_text)\n",
    "    rows.append({\"id\": setup_id, \"setup\": setup_text, \"punchline\": out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f6be0a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>setup</th>\n",
       "      <th>punchline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Идёт мужик по лесу</td>\n",
       "      <td>и видит — крокодил сидит Он подумал: \"Хорошо,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Встречаются два друга</td>\n",
       "      <td>— Дорогая, ты вчера была на свадьбе! - Ой, я ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Приходят мужик в бар</td>\n",
       "      <td>— Дорогой, ты не хочешь меня с женой? - Нет! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Жена говорит мужу</td>\n",
       "      <td>в постели: — Дорогой, ты мне не присножался!-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Приходят альфа, бета и гамма в бар</td>\n",
       "      <td>Альфы скидывают 20%, бета — 50%, а гамма - 75...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                               setup  \\\n",
       "0   1                  Идёт мужик по лесу   \n",
       "1   2               Встречаются два друга   \n",
       "2   3                Приходят мужик в бар   \n",
       "3   4                   Жена говорит мужу   \n",
       "4   5  Приходят альфа, бета и гамма в бар   \n",
       "\n",
       "                                           punchline  \n",
       "0   и видит — крокодил сидит Он подумал: \"Хорошо,...  \n",
       "1   — Дорогая, ты вчера была на свадьбе! - Ой, я ...  \n",
       "2   — Дорогой, ты не хочешь меня с женой? - Нет! ...  \n",
       "3   в постели: — Дорогой, ты мне не присножался!-...  \n",
       "4   Альфы скидывают 20%, бета — 50%, а гамма - 75...  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(rows)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"anecdotes.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
